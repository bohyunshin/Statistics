#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
% LaTeX에서 한글사용을 위해 사용해야하는 패키지
\usepackage[hangul]{kotex}
\setmainhangulfont{함초롬바탕} % 메인 한글폰트를 지정해줌


% 페이지 스타일 'fancy'를 사용하게 되면, 페이지 윗부분에 줄을 하나 그어줌.
% fancy 스타일을 사용할때 사용할수 있는 옵션은 아래와 같다.
%\lhead{CSE5850-01} % 줄 왼쪽 부분에 적을 내용
%\chead{Project Proposals} % 가운데 부분
%\rhead{신원용 교수님} % 오른쪽 부분
%=====================================%

% \renewcommand\footrulewidth{0.4pt}  % 페이지번호 위에 직선을그어주는 명령어




%=== 문서의 줄간격을 수정해주는 패키지 ===%
\usepackage{setspace} 
\setstretch{1.5} % 간격 임의로 지정 
% \onehalfspacing  한칸반 간격인것 같음
%=====================================%

\usepackage{tikz} % LaTeX으로 Graphical한 작업을 할때 사용하는 패키지

%=== pseudo code ===%
\usepackage{algorithm,algpseudocode}


\usepackage{hyperref} % 하이퍼링크 색깔 바꿔주기 위해

% 아래 옵션을 활성화시키면 하이퍼링크걸린 문자들의 색깔이 red로 변함
%\hypersetup{         
%    colorlinks,
%    citecolor=red,
%    filecolor=red,
%    linkcolor=red,
%    urlcolor=red
%}


%\usepackage{multicol} % 표지는 one-column, 본문은 two-column 적용해주기 위해
% 위 명령어를 활성화 시켜준 뒤
% \begin{multicols}{2}    \end{multicols} 사이에 본문을 작성하면
% 그 부분만 column이 나눠짐
\end_preamble
\options most, usenames, dvipsnames
\use_default_options true
\begin_modules
tcolorbox
theorems-ams
knitr
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding utf8-plain
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\output_sync_macro "\synctex=1"
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic true
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 3cm
\rightmargin 2cm
\bottommargin 3cm
\secnumdepth 2
\tocdepth 2
\paragraph_separation skip
\defskip bigskip
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 2
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\b}{\beta}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\a}{\alpha}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ddd}{\cdots}
\end_inset


\begin_inset FormulaMacro
\newcommand{\shat}[1]{\hat{#1}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\lhat}[1]{\widehat{#1}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\inf}{\infty}
\end_inset


\begin_inset FormulaMacro
\newcommand{\lam}{\lambda}
\end_inset


\begin_inset FormulaMacro
\newcommand{\df}[2]{\dfrac{#1}{#2}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ss}[1]{\left(#1\right)}
\end_inset


\begin_inset FormulaMacro
\newcommand{\mm}[1]{\left\{  #1\right\}  }
\end_inset


\begin_inset FormulaMacro
\newcommand{\ll}[1]{\left[#1\right]}
\end_inset


\begin_inset FormulaMacro
\newcommand{\si}{\sigma}
\end_inset


\begin_inset FormulaMacro
\newcommand{\rr}[1]{\sqrt{#1}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\d}{\cdot}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ones}{\,}
\end_inset


\begin_inset FormulaMacro
\newcommand{\twos}{\:}
\end_inset


\begin_inset FormulaMacro
\newcommand{\threes}{\;}
\end_inset


\begin_inset FormulaMacro
\renewcommand{\d}{\delta}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ep}{\epsilon}
\end_inset


\begin_inset FormulaMacro
\newcommand{\pro}{\times}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ovv}[1]{\overline{#1}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ra}{\longrightarrow}
\end_inset


\begin_inset FormulaMacro
\newcommand{\bold}[1]{\boldsymbol{#1}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\below}[2]{\underset{#2}{#1}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\pp}{\partial}
\end_inset


\begin_inset FormulaMacro
\newcommand{\bb}[1]{\mathbf{#1}}
\end_inset


\end_layout

\begin_layout Standard
1.
 Mathematical derivation of cyclical coordinate descent algorithm of Logistic
 Regression with NO PENALTY
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\bb y=(y_{1},\ddd,y_{n})^{'},\threes\bb X=(\bold 1,\bb x_{1},\ddd,\bb x_{p}),\threes\bb x_{j}=(x_{1j},\ddd,x_{nj})^{'},\threes\bold{\b}=(\b_{0},\ddd,\b_{p}),\threes\si(x)=\ll{1+exp(-x)}^{-1},\threes p_{i}=\si(\bold{\b}^{'}\bb x_{i})$
\end_inset

 .
 Then, the log likelihood of logistic regression is
\begin_inset Formula 
\[
L(\bold{\b}\mid\bb x)=\prod_{i=1}^{n}p_{i}^{y_{i}}(1-p_{i})^{1-y_{i}}\tag{1}
\]

\end_inset

Maximizing (1) is equivalent to minimize
\begin_inset Formula 
\[
{\cal L}=-log\ones L(\bold{\b}\mid\bb x)\tag{2}
\]

\end_inset

If 
\begin_inset Formula ${\cal L}$
\end_inset

 in (2) is convex function, we could apply Newton's method to get numerical
 solution of (2).
 Let's verify this step by step
\end_layout

\begin_layout Standard
Deriving 
\begin_inset Formula $\nabla_{\bold{\b}}{\cal L}$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\df{\pp}{\pp\b_{j}}logp=\df{\pp}{\pp\beta_{j}}\ss{log\df 1{1+exp(-\bold{\b}^{'}\bb x)}}=\df{x_{j}exp(-\bold{\b}^{'}\bb x)}{1+exp(-\bold{\b}^{'}\bb x)}=\df{x_{j}}{1+exp(\bold{\b}^{'}\bb x)}=x_{j}(1-p)$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\df{\pp}{\pp\b_{j}}log(1-p)=\df{\pp}{\pp\beta_{j}}\mm{-\bold{\b}^{'}\bb x-log(1+exp(-\bold{\b}^{'}\bb x))}=-x_{j}+x_{j}(1-p)=-px_{j}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\therefore\df{\pp}{\pp\b_{j}}{\cal L} & =-\sum_{i=1}^{n}\mm{y_{i}x_{ij}(1-p_{i})+(1-y_{i})(-p_{i}x_{ij})}\\
 & =-\sum_{i=1}^{n}\mm{y_{i}x_{ij}-y_{i}x_{ij}p_{i}-p_{i}x_{ij}+y_{i}p_{i}x_{ij}}\\
 & =\sum_{i=1}^{n}x_{ij}(p_{i}-y_{i})
\end{align*}

\end_inset


\begin_inset Formula 
\[
\therefore\nabla_{\bold{\b}}{\cal L}=\bb X^{'}(\bb p-\bb y)\tag{3}
\]

\end_inset

Because gradient w.r.t.
 
\begin_inset Formula $\bold{\b}$
\end_inset

 is not linear in 
\begin_inset Formula $\bold{\b}$
\end_inset

, we need to apply Newton's method.
\end_layout

\begin_layout Standard
Deriving 
\begin_inset Formula $\nabla_{\bold{\b}}^{2}{\cal L}$
\end_inset

 (Hessian Matrix)
\begin_inset Newline newline
\end_inset

If we show that the Hessian matrix is positive semi-definite, 
\begin_inset Formula ${\cal L}$
\end_inset

 is convex function and we can apply Newton's method to get numerical solution
 in (3).
 Note that
\begin_inset Formula 
\[
\df{\pp^{2}}{\pp\b_{j}\pp\b_{k}}{\cal L}=\sum_{i=1}^{n}x_{ij}\df{\pp}{\pp\b_{k}}p_{i}
\]

\end_inset

Because 
\begin_inset Formula $\pp logp=\df 1p\pp p\Longleftrightarrow\pp p=p\ones\pp logp=px_{j}(1-p),$
\end_inset

 it is obviout that 
\begin_inset Formula $\df{\pp}{\pp\b_{k}}p_{i}=x_{ik}p_{i}(1-p_{i})$
\end_inset

.
 Therefore,
\begin_inset Formula 
\begin{align*}
\sum_{i=1}^{n}x_{ij}\df{\pp}{\pp\b_{k}}p_{i} & =\sum_{i=1}^{n}x_{ij}x_{ik}p_{i}(1-p_{i})\\
 & =\bb x_{j}^{'}\bb W\bb x_{k}
\end{align*}

\end_inset


\begin_inset Formula 
\[
where\threes\bb W=\ll{\begin{array}{cccc}
p_{1}(1-p_{1})\\
 & \ddots\\
 &  & \ddots\\
 &  &  & p_{n}(1-p_{n})
\end{array}}
\]

\end_inset


\begin_inset Formula 
\[
\therefore\nabla_{\bold{\b}}^{2}{\cal L}=\bb X^{'}\bb W\bb X=\ss{\bb W^{1/2}\bb X}^{'}\ss{\bb W^{1/2}\bb X}\tag{4}
\]

\end_inset

The eigen values of 
\begin_inset Formula $\nabla_{\bold{\b}}^{2}{\cal L}$
\end_inset

 are non-negative, so 
\begin_inset Formula $\nabla_{\bold{\b}}^{2}{\cal L}$
\end_inset

 is p.s.d.
 matrix.
 Therefore, 
\begin_inset Formula ${\cal L}$
\end_inset

 is convex function w.r.t.
 
\begin_inset Formula $\bold{\b}$
\end_inset

.
\end_layout

\begin_layout Standard
Newton's method
\begin_inset Newline newline
\end_inset

The general iterative equation for getting numerical solution via Newton's
 method is
\begin_inset Formula 
\[
\bold{\b}_{t+1}=\bold{\b}_{t}-\bb H^{-1}\bb g
\]

\end_inset

where 
\begin_inset Formula $\bb H$
\end_inset

 is Hessian matrix and 
\begin_inset Formula $\bb g$
\end_inset

 is gradient w.r.t.
 
\begin_inset Formula $\bold{\b}$
\end_inset

.
 Using (3), (4) results, we get
\begin_inset Formula 
\begin{align*}
\bold{\b}_{t+1} & =\bold{\b}_{t}-\bb H^{-1}\bb g\\
 & =\bold{\b}_{t}-\ss{\bb X^{'}\bb W\bb X}^{-1}\bb X^{'}(\bb p-\bb y)\\
 & =\ss{\bb X^{'}\bb W\bb X}^{-1}\bb X^{'}\bb W\ss{\bb X\bold{\b}_{t}-\bb W^{-1}(\bb p-\bb y)}\\
 & =\ss{\bb X^{'}\bb W\bb X}^{-1}\bb X^{'}\bb W\bb z_{t}
\end{align*}

\end_inset


\begin_inset Formula 
\[
where\threes z_{t}=\bb X\bold{\b}_{t}-\bb W^{-1}(\bb p-\bb y)\tag{5}
\]

\end_inset

From (5), we can see that 
\begin_inset Formula $\bold{\b}_{t+1}$
\end_inset

 is solution of weighted least squares, where we minimize following quantity.
\begin_inset Formula 
\[
argmin_{\bold{\b}}\ones\sum_{i=1}^{n}b_{i}(z_{i}-\bold{\b}^{'}\bb x_{i})^{2},\threes b_{i}=p_{i}(1-p_{i})\tag{6}
\]

\end_inset

In conclusion, to get mle, minimizing quantity (2) is equivalent to minimizing
 quantity (6).
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
2.
 Adding Lasso Penalty to Logistic Regression.
\end_layout

\begin_layout Standard
Note that the objective function of logistic regression with lasso penalty
 will be
\begin_inset Formula 
\[
Q(\bold{\b})=-log\ones L(\bold{\b}\mid\bb x)+\lam\sum_{j=1}^{p}\mid\b_{j}\mid\tag{7}
\]

\end_inset

However, we show that minimizing 
\begin_inset Formula $Q(\bold{\b})$
\end_inset

 is equal to minimizing
\begin_inset Formula 
\[
Q(\bold{\b})^{N}=\sum_{i=1}^{n}b_{i}(z_{i}-\bold{\b}^{'}\bb x_{i})^{2}+\lam\sum_{j=1}^{p}\mid\b_{j}\mid\tag{8}
\]

\end_inset

Now, we can derive cyclical coordinate descent using gradient and subgradient
 w.r.t.
 
\begin_inset Formula $\bold{\b}$
\end_inset

.
\begin_inset Formula 
\begin{align*}
\df{\pp}{\pp\b_{j}}\ss{\sum_{i=1}^{n}b_{i}(z_{i}-\bold{\b}^{'}\bb x_{i})^{2}} & =-2\sum_{i=1}^{n}b_{i}x_{ij}\ss{z_{i}-\sum_{j=0}^{p}\b_{j}x_{ij}}\\
 & =-2\sum_{i=1}^{n}b_{i}x_{ij}\ss{z_{i}-\sum_{k\neq j}^{p}\b_{j}x_{ij}}+2\b_{j}\sum_{i=1}^{n}b_{i}x_{ij}^{2}\\
 & =-2\rho_{j}+2\b_{j}q_{j}
\end{align*}

\end_inset

The subgradient of 
\begin_inset Formula $\lam\mid\b_{j}\mid$
\end_inset

 is
\begin_inset Formula 
\[
\lam\ones\pp_{\b_{j}}\mid\b_{j}\mid=\begin{cases}
-\lam & \b_{j}<0\\{}
[-\lam,\lam] & \b_{j}=0\\
\lam & \b_{j}>0
\end{cases}
\]

\end_inset

Therefore,
\begin_inset Formula 
\begin{align*}
\pp_{\b_{j}}\ss{Lasso\ones Cost}= & -2\rho_{j}+2\b_{j}q_{j}+\begin{cases}
-\lam & \b_{j}<0\\{}
[-\lam,\lam] & \b_{j}=0\\
\lam & \b_{j}>0
\end{cases}\\
 & =\begin{cases}
-2\rho_{j}+2\b_{j}q_{j}-\lam & \b_{j}<0\\{}
[-2\rho_{j}-\lam,-2\rho_{j}+\lam] & \b_{j}=0\\
-2\rho_{j}+2\b_{j}q_{j}+\lam & \b_{j}>0
\end{cases}
\end{align*}

\end_inset

Finally, setting subgradient to zero, we get the soft thresholding as
\begin_inset Formula 
\[
\shat{\b}_{j}=\begin{cases}
\df{\rho_{j}+\lam/2}{q_{j}} & \rho_{j}<-\lam/2\\
0 & -\lam/2\leq\rho_{j}\leq\lam/2\\
\df{\rho_{j}-\lam/2}{q_{j}} & \lam/2<\rho_{j}
\end{cases}
\]

\end_inset


\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Cyclical Coordinate Descent for Penalized Logistic Regression
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hspace*{
\backslash
algorithmicindent} 
\backslash
textbf{Input :} {$
\backslash
mathbf{y},
\backslash
mathbf{X}, 
\backslash
lambda$}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hspace*{
\backslash
algorithmicindent} 
\backslash
textbf{Output : } {$
\backslash
boldsymbol{
\backslash
hat{
\backslash
beta}}$}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
begin{algorithmic}
\end_layout

\begin_layout Plain Layout


\backslash
State $
\backslash
text{Initialize } 
\backslash
hat{
\backslash
beta}_j$
\end_layout

\begin_layout Plain Layout


\backslash
State $
\backslash
text{Precompute } q_j$
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	
\backslash
While {$
\backslash
text{not converged}$}
\end_layout

\begin_layout Plain Layout

		
\backslash
State $
\backslash
text{Compute } 
\backslash
rho_j$
\end_layout

\begin_layout Plain Layout

		
\backslash
State $
\backslash
text{Compute } 
\backslash
hat{
\backslash
beta}_j$
\end_layout

\begin_layout Plain Layout

	
\backslash
EndWhile
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The pseudo code for CCD is summarized in Algorithm 1.
\end_layout

\end_body
\end_document
